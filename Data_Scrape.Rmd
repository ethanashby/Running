---
title: "Data_Scrape"
output: pdf_document
---

```{r Natties Results}
library(tidyverse)
library(rvest)
library(pdftools)
library(xml2)
library(XML)
library(RCurl)
`%notin%` <- Negate(`%in%`)


#############################
####Natties Results Function from TFRRS
#############################

scrape_natties_data<-function(url, xpath_node){
  #url is the tfrrs url page for natties results
  #xpath is the xpath to the table you want to extract info from: ex. '/html/body/div[3]/div/div/div[3]/div[6]'
  #you can try changing the last number in brackets to choose which table you want
  times<-url %>%
    read_html() %>%
    html_node(xpath=xpath_node) %>%
    html_text(trim=TRUE) %>%
    stringr::str_split("\n") %>%
    unlist()
  #get rid of empty entries and trim whitespace
  times=times[times != ""]
  times=trimws(times)
  times=times[times != ""]
  #remove interactive table header
  times=times[-c(1:3)]
  #make dataframe with results
  times<-matrix(times, ncol=(match("1", times)-match("PL", times)), byrow=TRUE)
  colnames(times)<-times[1,]
  times<-as.data.frame(times, header=TRUE)[c(2:dim(times)[1]),]
  times$NAME<-gsub("\t", "", times$NAME)
  times
}

###############################
###2018 Results
###############################

url18<-"https://xc.tfrrs.org/results/xc/15028.html"

times18<-scrape_natties_data(url18, '/html/body/div[3]/div/div/div[3]/div[6]')

######################
###2017 Results
######################
url17<-"https://www.tfrrs.org/results/xc/13424/NCAA_Division_III_Cross_Country_Championships"

times17<-scrape_natties_data(url17, '/html/body/div[3]/div/div/div[3]/div[3]')

#####################
###2016 Results
#####################
url16<-"https://www.tfrrs.org/results/xc/11260/NCAA_Division_III_Cross_Country_Championships"

times16<-scrape_natties_data(url16, '/html/body/div[3]/div/div/div[3]/div[3]')

#####################
###2015 Results
####################
url15<-"https://www.tfrrs.org/results/xc/9349/NCAA_Division_III_Cross_Country_Championships"

times15<-scrape_natties_data(url15, '/html/body/div[3]/div/div/div[3]/div[3]')


#####################
###2014 Results
#####################
url14<-"https://www.tfrrs.org/results/xc/7654/NCAA_Division_III_Cross_Country_Championships"

times14<-scrape_natties_data(url14, '/html/body/div[3]/div/div/div[3]/div[6]')

#####################
###2013 Results
#####################
url13<-"https://www.tfrrs.org/results/xc/6216/NCAA_Division_III_Cross_Country_Championships"

times13<-scrape_natties_data(url13, '/html/body/div[3]/div/div/div[3]/div[6]')


#####################
###2012 Results
#####################
url12<-"https://www.tfrrs.org/results/xc/4798/2012_NCAA_Division_III_Cross_Country_Championships"

times12<-scrape_natties_data(url12, '/html/body/div[3]/div/div/div[3]/div[3]')
```

```{r}
#25 teams that have qualified for nationals for 5 straight years
teams<-intersect(intersect(intersect(intersect(unique(times18$TEAM), unique(times17$TEAM)), times16$TEAM), times15$TEAM), times14$TEAM)

#######
#NC (North Central)
#######
NClinks<-c(paste(rep("https://northcentralcardinals.com/sports/mens-cross-country/roster/"), c(2019:2012), sep=""))

pull_NC_roster<-function(year, omit) {
url<-paste(rep("https://northcentralcardinals.com/sports/mens-cross-country/roster/"), year, sep="")
roster<-url %>%
    read_html() %>%
    html_node(xpath='//*[@id="main-content"]') %>%
    html_text(trim=TRUE) %>%
    stringr::str_split("\n") %>%
    unlist()
#remove extraneous characters
roster=roster[roster != ""]
roster=trimws(roster)
roster=roster[roster != ""]
roster<-gsub("\t", "", roster)
roster<-gsub("\r", "", roster)
#remove stuff above and below names that we want
roster<-roster[-c(1:match("Name", roster)-1)]
roster<-roster[-c(match("Men's Cross Country Coaching Staff", roster):length(roster))]
#remove table headers
roster<-roster[-grep("Hide/Show", roster)]
roster<-roster[-grep("Full Bio", roster)]
roster<-roster[-grep("Roster", roster)]
#remove extra labels
indices<-c(grep("Freshman", roster), grep("Sophomore", roster), grep("Junior", roster), grep("Senior", roster))
indices_to_delete<-c()
for (i in 1:length(indices)){
  indices_to_delete<-c(indices_to_delete, indices[i], indices[i]+1, indices[i]+2)
}
roster<-roster[-indices_to_delete]
#remove transfer info
roster=roster[roster != ""]
roster<-gsub("Go", "HS Team", roster)
roster<-roster[-grep("Players", roster)]
for (i in 1:length(omit)){
roster<-roster[-grep(omit[i], roster)]
}
#return roster
roster<-matrix(roster, ncol=match("HS Team", roster), byrow=TRUE)
colnames(roster)<-roster[1,]
roster<-as.data.frame(roster, header=TRUE)[c(2:dim(roster)[1]),]
roster
}

pull_NC_roster(2019, omit=c("Monmouth College", "Harper College"))
pull_NC_roster(2018, omit=c("Univ. of Alabama", "Harper College", "Iowa State Univ."))
pull_NC_roster(2017, omit=c("Univ. of Alabama", "Univ. of Colorado", "Iowa State Univ.", "College of Lake County"))
pull_NC_roster(2016, omit=c("Univ. of Alabama", "Iowa State Univ.", "Univ. of Illinois-Chicago"))
pull_NC_roster(2015, omit=c("Univ. of Illinois-Chicago", "Univ. of Nebraska", "College of Lake County"))
pull_NC_roster(2014, omit=c("Univ. of Portland", "Univ. of Illinois-Chicago", "Univ. of Nebraska"))
pull_NC_roster(2013, omit=c("Univ. of Portland", "Univ. of Illinois-Chicago", "Univ. of Nebraska", "College of Lake County"))
pull_NC_roster(2012, omit=c("Ripon Coll.", "Oklahoma State Univ."))

##############
##Pomona Pitzer
#############
teams[2]

pull_PP_roster<-function(year){
  url<-paste("https://www.sagehens.com/sports/mxc/", year, "-", (year%%100)+1, "/roster?view=list", sep="")
  #get table info into R
  info<-url %>%
    read_html() %>%
    html_node(xpath=paste('//*[@id="mainbody"]/div[1]/div[2]', sep="")) %>%
    html_text(trim=TRUE) %>%
    stringr::str_split("\n") %>%
    unlist()
  #trim and remove unwanted stuff
  info<-gsub("\t", "", info)
  info<-trimws(info)
  info<-info[info != "Hometown/High School:"]
  info<-info[info != "College:"]
  info<-info[info != "Pomona"]
  info<-info[info != "Pitzer"]
  info<-info[info != "/"]
  info<-info[info != "Cl.:"]
  info<-info[info != ""]
  info<-gsub("FY", "Fr", info)
  info<-gsub("Fr.", "Fr", info)
  info<-gsub("Sr.", "Sr", info)
  info<-gsub("Jr.", "Jr", info)
  info<-gsub("So.", "So", info)
  info<-info[str_length(info) > 1]
  
  #read data into matrix
  roster<-matrix(ncol=4, nrow=floor(length(info)/5))
  for (i in 1:floor(length(info)/5)){
    roster[i,1]<-paste(info[5*i], info[5*i+1], sep=" ")
    roster[i,2]<-info[5*i+2]
    roster[i,3]<-info[5*i+3]
    roster[i,4]<-info[5*i+4]
  }
  #convert to df
  roster<-as.data.frame(roster)
  colnames(roster)<-c("Name", "Year", "Hometown", "High School")
  roster
}

pull_PP_roster(year=2012)


#########
###Wis.-La Crosse
#########
teams[3]

pull_WLC_roster<-function(year) {
url<-paste(rep("https://uwlathletics.com/sports/mens-cross-country/roster/"), year, sep="")
roster<-url %>%
    read_html() %>%
    html_node(xpath='//*[@id="main-content"]') %>%
    html_text(trim=TRUE) %>%
    stringr::str_split("\n") %>%
    unlist()
#remove extraneous characters
roster=roster[roster != ""]
roster=trimws(roster)
roster=roster[roster != ""]
roster<-gsub("\t", "", roster)
roster<-roster %>% str_replace("\r", "")
#remove stuff above and below names that we want
roster<-roster[-c(1:match("Name", roster)-1)]
roster<-roster[-c(grep("Men's Cross Country Coaching Staff", roster):length(roster))]
#remove table headers
roster<-roster[-grep("Hide/Show", roster)]
roster<-roster[-grep("Full Bio", roster)]
roster<-roster[-grep("Roster", roster)]
#remove extra labels
if (year<2017){
indices<-c(seq(9, 142, by=6), seq(10, 142, by=6))
roster<-roster[-indices]}
else{
indices<-c(grep("Freshman", roster), grep("Sophomore", roster), grep("Junior", roster), grep("Senior", roster))
indices_to_delete<-c()
for (i in 1:length(indices)){
  indices_to_delete<-c(indices_to_delete, indices[i], indices[i]+1, indices[i]+2)
}
roster<-roster[-indices_to_delete]
}
#remove transfer info
roster=roster[roster != ""]
roster<-gsub("Go", "HS Team", roster)
if ("Class" %notin% roster) {
  roster=c("Class", roster)
}
roster<-roster[-match("Players", roster)]
#return roster
roster<-matrix(roster, ncol=4, byrow=TRUE)
colnames(roster)<-roster[1,]
roster<-as.data.frame(roster, header=TRUE)[c(2:dim(roster)[1]),]
roster
}

pull_WLC_roster(2019)
pull_WLC_roster(2018)
pull_WLC_roster(2016)
pull_WLC_roster(2012)

```


```{r}
#read in the data as html and select node that gives mens results, then split by "/n" character and unlist as character vector
times17<-url17 %>%
  read_html() %>%
  html_node(xpath='/html/body/div[3]/div/div/div[3]/div[3]') %>%
  html_text(trim=TRUE) %>%
  stringr::str_split("\n") %>%
  unlist() 
#remove empty entries and trime whitespace
times17=times17[times17 != ""]
times17=trimws(times17)
#remove empty entries and interactive table header
times17=times17[times17 != ""]
times17=times17[-c(1:3)]
#make dataframe with results
times17<-matrix(times17, ncol=7, byrow=TRUE)
colnames(times17)<-times17[1,]
times17<-as.data.frame(times17, header=TRUE)[c(2:dim(times17)[1]),]
times17$NAME<-gsub("\t", "", times17$NAME)

#read in the data as html and select node that gives mens results, then split by "/n" character and unlist as character vector
times18<-url18 %>%
  read_html() %>%
  html_node(xpath='/html/body/div[3]/div/div/div[3]/div[6]') %>%
  html_text(trim=TRUE) %>%
  stringr::str_split("\n") %>%
  unlist()
#remove empty entries and trime whitespace
times18=times18[times18 != ""]
times18=trimws(times18)
times18=times18[times18 != ""]
#remove empty entries and interactive table header
times18=times18[-c(1:3)]
#make dataframe with results, use match indices to infer number of columns
times18<-matrix(times18, ncol=(match("1", times18)-match("PL", times18)), byrow=TRUE)
colnames(times18)<-times18[1,]
times18<-as.data.frame(times18, header=TRUE)[c(2:dim(times18)[1]),]
times18
```

