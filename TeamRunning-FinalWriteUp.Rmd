---
title: "Team Running Final Write Up"
author: "Ethan Ashby, Daniel Rosen, Nate Stringham"
date: "12/14/2019"
output: html_document
---

#Summary
The ability of a program to peak its runners well at the end of the season is often what determines national champions. 
To determine how well programs peak their athletes, we will use simulations of cross country results to score a hypothetical "national meet", and evaluate these simulated results against the real results of the national meet to evaluate good and bad programs. To run the simulation, we collect results for each relevant athlete in the Divison at each meet. For each athlete, we maintain a vector of adjusted times from the current season. Then we sample from a distribution created from athlete's vector and sort the athletes into a meet ranking, which we then score as a cross country meet. We compare the actual nationals result from that year to our simulated result to determine how well a team peaked. We can do this over a number of years to evaluate different programs. We assign a score to each program based on how consistently they peaked at the national meet and how far they exceeded our simulated expectation of their finish at the national meet. IF we have time we'll make a shiny app!

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r Packages, cache=TRUE, echo=FALSE, message=FALSE, warning=FALSE}
library(magrittr)
library(rvest)
library(xml2)
library(stringi)
library(dplyr)
library(stringr)
library(tidyverse)
library(ggplot2)
library(plotly)
library(RColorBrewer)
library(colorspace)

?distinct()
```

The first step is to build a scraper which is capable of retrieving data from the official database of NCAA cross country and track and field times, TFRRS. The database is very robust but has no API for statisticians to pull data in a reasonable way, so this actually turns out to be quite difficult. TFRRS also threatens users with cease and desist messages if they detect too much traffic from one user, or if they notice a blog post on the web about it. Despite its draconian policies with regard to data usage, they remain far and away the most robust way to access data on collegiate runners. 

This first codechunk compiles results from each of the regional meets into a single data frame. To qualify for the national meet, each team must compete in a regional meet. 2 teams automatically qualify from each region and the remainder of the nationals field is selected through a well-documented selection process. 

```{r Initial Codestuff, cache=TRUE, echo=FALSE, message=FALSE, warning=FALSE}
###Initial codestuff
urls <- c("https://www.tfrrs.org/results/xc/16561", "https://www.tfrrs.org/results/xc/16562",
           "https://www.tfrrs.org/results/xc/16563", "https://www.tfrrs.org/results/xc/16564",
          "https://www.tfrrs.org/results/xc/16565", "https://www.tfrrs.org/results/xc/16567", 
          "https://www.tfrrs.org/results/xc/16568", "https://www.tfrrs.org/results/xc/16724")

nationals_urls <- c("https://www.tfrrs.org/results/xc/15028", "https://www.tfrrs.org/results/xc/13424",
                    "https://www.tfrrs.org/results/xc/9349/", "https://www.tfrrs.org/results/xc/11260/",
                    "https://www.tfrrs.org/results/xc/6216/")


df <- data.frame(PL=integer(),
                 NAME=character(),
                 YEAR=character(),
                 TEAM=character(),
                 TIME=character(),
                 COURSE=character(),
                 DATE=character()
                 )

for(url in urls) {
  webpage <- read_html(url)
  print("read webpage")
  table_of_tables <- xml_find_all(webpage, "//table") %>% html_table
  titles <- html_nodes(webpage, "h3")
  courses <- html_nodes(webpage, ".inline-block")
  table_index <- 2
  for(i in 1:length(titles[])) {
    if(grepl("8K|8000|8,000|8k", titles[i][1])) {
      table_index <- i
      print(table_index)
      current_data <- table_of_tables[[table_index]] %>% select(NAME, YEAR, TEAM, TIME)
      current_data <- current_data %>% mutate(DATE=html_text(courses[4][1]))
      if(str_length(html_text(courses[5][1])) > 4) {
        current_data <- current_data %>% mutate(COURSE=html_text(courses[5][1]))
      } else {
        current_data <- current_data %>% mutate(COURSE="NA")
      }
      df <- rbind(df, current_data)
      break
    }
  }
}

```

Now we are ready to get a more relevant and complex data set, including the data which we gathered above. This code chunk grabs all of the names of teams which competed at the national meet.
```{r Get Team Names, cache=TRUE, echo=FALSE, message=FALSE, warning=FALSE}
###########
##Meet Results for National Qualifiers
###########

#first get team names
df <- data.frame(PL=integer(),
                 NAME=character(),
                 YEAR=character(),
                 TEAM=character(),
                 TIME=character(),
                 COURSE=character(),
                 DATE=character()
)

url="https://www.tfrrs.org/results/xc/16726/NCAA_Division_III_Cross_Country_Championships"
webpage <- read_html(url)
print("read webpage")
table_of_tables <- xml_find_all(webpage, "//table") %>% html_table
titles <- html_nodes(webpage, "h3")
courses <- html_nodes(webpage, ".inline-block")
table_index <- 2
for(i in 1:length(titles[])) {
  if(grepl("8K|8000|8,000|8k", titles[i][1])) {
    table_index <- i
    print(table_index)
    current_data <- table_of_tables[[table_index]] %>% select(NAME, YEAR, TEAM, TIME)
    current_data <- current_data %>% mutate(DATE=html_text(courses[4][1]))
    if(str_length(html_text(courses[5][1])) > 4) {
      current_data <- current_data %>% mutate(COURSE=html_text(courses[5][1]))
    } else {
      current_data <- current_data %>% mutate(COURSE="NA")
    }
    df <- rbind(df, current_data)
    break
  }
}

teamnames<-unique(df$TEAM)
```
Now we are ready to get a more interesting data set. The NCAA cross-country regular season is about 8 weeks long, and most teams compete in anywhere from 4-6 meets over these weeks. To get a hold of these meets, we scrape each qualified team's TFRRS page, which has a schedule of meets which they competed at.
```{r URLS, cache=TRUE, echo=FALSE, message=FALSE, warning=FALSE}
#####Pulling meet results for national qualifiers
urls<-c("https://www.tfrrs.org/teams/MD_college_m_Stevenson.html", "https://www.tfrrs.org/teams/MN_college_m_Carleton.html", 
        "https://www.tfrrs.org/teams/CA_college_m_Claremont_Mudd_Scripps.html", "https://www.tfrrs.org/teams/MD_college_m_Johns_Hopkins.html",
        "https://www.tfrrs.org/teams/WI_college_m_Wis_La_Crosse.html", "https://www.tfrrs.org/teams/WI_college_m_Wis_Whitewater.html",
        "https://www.tfrrs.org/teams/CA_college_m_Pomona_Pitzer.html", "https://www.tfrrs.org/teams/IL_college_m_U_of_Chicago.html",
        "https://www.tfrrs.org/teams/MA_college_m_Williams.html", "https://www.tfrrs.org/teams/IL_college_m_North_Central_IL.html", 
        "https://www.tfrrs.org/teams/OH_college_m_Otterbein.html", "https://www.tfrrs.org/teams/WI_college_m_Wis_Platteville.html",
        "https://www.tfrrs.org/teams/xc/GA_college_m_Emory.html", "https://www.tfrrs.org/teams/xc/OH_college_m_John_Carroll.html",
        "https://www.tfrrs.org/teams/NY_college_m_RPI.html", "https://www.tfrrs.org/teams/xc/MI_college_m_Calvin.html", 
        "https://www.tfrrs.org/teams/MO_college_m_Washington_U.html", "https://www.tfrrs.org/teams/WI_college_m_Wis_Oshkosh.html",
        "https://www.tfrrs.org/teams/IA_college_m_Wartburg.html", "https://www.tfrrs.org/teams/NY_college_m_Geneseo_St.html", 
        "https://www.tfrrs.org/teams/CA_college_m_Redlands.html", "https://www.tfrrs.org/teams/xc/NY_college_m_St_Lawrence.html",
        "https://www.tfrrs.org/teams/PA_college_m_Elizabethtown.html", "https://www.tfrrs.org/teams/MA_college_m_MIT.html",
        "https://www.tfrrs.org/teams/MN_college_m_Hamline.html", "https://www.tfrrs.org/teams/xc/VT_college_m_Middlebury.html",
        "https://www.tfrrs.org/teams/xc/ME_college_m_Colby.html", "https://www.tfrrs.org/teams/WI_college_m_Wis_Eau_Claire.html",
        "https://www.tfrrs.org/teams/xc/PA_college_m_Haverford.html", "https://www.tfrrs.org/teams/OH_college_m_Franciscan-OH.html",
        "https://www.tfrrs.org/teams/CT_college_m_Conn_College.html", "https://www.tfrrs.org/teams/xc/PA_college_m_Carnegie_Mellon.html",
        "https://www.tfrrs.org/teams/xc/MN_college_m_St_Thomas.html", "https://www.tfrrs.org/teams/WI_college_m_Lawrence.html",
        "https://www.tfrrs.org/teams/xc/WI_college_m_Wis_Stout.html", "https://www.tfrrs.org/teams/NY_college_m_Brockport_St.html",
        "https://www.tfrrs.org/teams/xc/MA_college_m_Amherst.html", "https://www.tfrrs.org/teams/NJ_college_m_Rowan.html",
        "https://www.tfrrs.org/teams/xc/KY_college_m_Berea.html", "https://www.tfrrs.org/teams/xc/CA_college_m_UC_Santa_Cruz.html",
        "https://www.tfrrs.org/teams/MN_college_m_Gustavus_Adolphus.html", "https://www.tfrrs.org/teams/OH_college_m_Mount_Union.html",
        "https://www.tfrrs.org/teams/PA_college_m_Marywood.html", "https://www.tfrrs.org/teams/PA_college_m_Moravian.html",
        "https://www.tfrrs.org/teams/IN_college_m_DePauw.html", "https://www.tfrrs.org/teams/MA_college_m_Bridgewater_St.html",
        "https://www.tfrrs.org/teams/xc/MN_college_m_St_Olaf.html", "https://www.tfrrs.org/teams/VA_college_m_Southern_Virginia.html",
        "https://www.tfrrs.org/teams/xc/NY_college_m_Ithaca.html", "https://www.tfrrs.org/teams/CA_college_m_Caltech.html",
        "https://www.tfrrs.org/teams/xc/NY_college_m_Oneonta.html","https://www.tfrrs.org/teams/xc/OH_college_m_Case_Western.html",
        "https://www.tfrrs.org/teams/TX_college_m_Trinity_TX.html", "https://www.tfrrs.org/teams/IA_college_m_Loras.html",
        "https://www.tfrrs.org/teams/MA_college_m_WPI.html", "https://www.tfrrs.org/teams/PA_college_m_Widener.html",
        "https://www.tfrrs.org/teams/WI_college_m_Wis_Stevens_Point.html", "https://www.tfrrs.org/teams/VA_college_m_Mary_Washington.html",
        "https://www.tfrrs.org/teams/OR_college_m_Lewis__Clark.html", "https://www.tfrrs.org/teams/xc/ME_college_m_Bates.html",
        "https://www.tfrrs.org/teams/IA_college_m_Luther.html", "https://www.tfrrs.org/teams/VA_college_m_Lynchburg.html",
        "https://www.tfrrs.org/teams/VA_college_m_Virginia_Wesleyan.html", "https://www.tfrrs.org/teams/IN_college_m_Trine.html",
        "https://www.tfrrs.org/teams/MA_college_m_Suffolk.html", "https://www.tfrrs.org/teams/TN_college_m_Rhodes.html",
        "https://www.tfrrs.org/teams/ME_college_m_U_of_New_England.html", "https://www.tfrrs.org/teams/PA_college_m_Muhlenberg.html",
        "https://www.tfrrs.org/teams/ME_college_m_Bowdoin.html", "https://www.tfrrs.org/teams/NJ_college_m_Ramapo.html",
        "https://www.tfrrs.org/teams/CT_college_m_Trinity_CT.html", "https://www.tfrrs.org/teams/CA_college_m_Occidental.html",
        "https://www.tfrrs.org/teams/CO_college_m_Colorado_College.html", "https://www.tfrrs.org/teams/WA_college_m_Puget_Sound.html",
        "https://www.tfrrs.org/teams/NY_college_m_New_Paltz_St.html", "https://www.tfrrs.org/teams/IL_college_m_Benedictine_IL.html",
        "https://www.tfrrs.org/teams/CA_college_m_La_Verne.html", "https://www.tfrrs.org/teams/NJ_college_m_TCNJ.html",
        "https://www.tfrrs.org/teams/AR_college_m_Ozarks.html", "https://www.tfrrs.org/teams/MN_college_m_Bethel_MN.html",
        "https://www.tfrrs.org/teams/NY_college_m_NYU.html", "https://www.tfrrs.org/teams/OH_college_m_Heidelberg.html"
        )

```

*2019*

```{r scraper, cache=TRUE, echo=FALSE, message=FALSE, warning=FALSE}
team_races<-list()
for(url in urls) {
  print(url)
  webpage <- read_html(url)
  print("read webpage")
  links_tmp=str_match_all(webpage, "<a href=\"(.*?)\"")
  links=links_tmp[[1]][,2]
  links=links[grepl("/results/", links)]
  links=unique(links)
  links=links[setdiff(1:length(links), grep('[[:digit:]]{5}/[[:digit:]]{6}', links))]
  table_of_tables <- xml_find_all(webpage, "//table") %>% html_table
  index=grep("DATE", table_of_tables)
  dates_and_links=table_of_tables[[index]]
  dates_and_links<-cbind(dates_and_links, links)
  dates_and_links<-dates_and_links %>% filter(grepl("/results/xc/", dates_and_links$links))
  name=stringr::str_split(url, "_m_")[[1]][2]
  name=stringr::str_split(name, ".html")[[1]][1]
  dates_and_links=dates_and_links %>% filter(grepl(2019, dates_and_links$DATE))
  dates_and_links$links<-paste("https:", gsub("%0A", "%250A", dates_and_links$links), sep="")
  team_races[[name]]<-dates_and_links
}

names(team_races)<-teamnames

#Now we have a list 'team_races' that contains dates, meets, and links to results for every race run in 2019 for
#all national qualifiers
  
#####Construct list of race times for qualifying teams 
season_results<-list()

for (j in 1:length(team_races)){
racelinks<-team_races[[j]]$links
print(names(team_races)[j])

resdf <- data.frame(PL=integer(),
                 NAME=character(),
                 YEAR=character(),
                 TEAM=character(),
                 TIME=character(),
                 COURSE=character(),
                 DATE=character(),
                 MEETNAME=character()
)

for(url in racelinks) {
  print(url)
  webpage <- read_html(url)
  print("read webpage")
  table_of_tables <- xml_find_all(webpage, "//table") %>% html_table
  titles <- html_nodes(webpage, "h3")
  meetnamelinks <-html_nodes(webpage, "a")
  courses <- html_nodes(webpage, ".inline-block")
  table_index <- 2
    #generate possible indices
    
    if(length(titles)>length(table_of_tables)){titles=titles[2:length(titles)]}
    if(length(titles)<length(table_of_tables)){function(){}}
    else{
    poss_indices=grep("8K|8000|8,000|8k", titles)
    if (length(poss_indices)==0){function(){}}
    else{
    for(i in 1:length(poss_indices)) {
    if(grepl("Individual", titles[poss_indices[i]])) {
      table_index <- poss_indices[i]
      print(table_index)
      current_data <- table_of_tables[[table_index]] %>% select(NAME, YEAR, TEAM, TIME)
      current_data <- current_data %>% mutate(DATE=html_text(courses[4][1]))
      current_data <- current_data %>% mutate(MEETNAME=html_text(meetnamelinks[[14]]))
      if(str_length(html_text(courses[5][1])) > 4) {
        current_data <- current_data %>% mutate(COURSE=html_text(courses[5][1]))
      } else {
        current_data <- current_data %>% mutate(COURSE="NA")
      }
      resdf <- rbind(resdf, current_data)
    }}
  }
}
}
season_results[[j]]<-resdf %>% filter(TEAM==names(team_races)[j])
}


all_results <- data.frame(NAME=character(),
                 YEAR=character(),
                 TEAM=character(),
                 TIME=character(),
                 COURSE=character(),
                 DATE=character(),
                 MEETNAME=character())
for(i in seq(1, 82)) {
    all_results = rbind(all_results, season_results[[i]])
}
all_results <- all_results %>% mutate(MEETNAME=str_trim(MEETNAME))
write.csv(all_results, "2019_all_results3.csv")
```
We grab all of the results from each of the meets that an NCAA qualifying team raced during the regular season. Then, we filter for the HTML table which has some variation of 8k, or 8000m, as a title -- this is the race distance that the men compete at. 


Now, each course runs a little bit differently. There are many factors which go into this, such as course surface, course condition, weather conditions, and elevation profiles. However, since athletes run on multiple courses per year, there is a reasonable way to make adjustments for these differences. Bijan Mazaheri, a Caltech PhD. student, ran a nifty program to generate these adjustments. The idea is to look at two courses at a time, and pick all the athletes which ran on both. Then, take the difference in times between each athlete, and take the mean of all those times to generate a relative difference in times between the two courses. This is the pairwise adjustment for these two courses. To convert a time from the first course to the second course, add this adjustment factor to each athlete's time. 

Repeat this for each pair of courses which had similar runners. When all of the pairwise adjustments have been calculated, pick one course to serve as a baseline, and then use least-squares to pick a single adjustment for each course. 

Since Bijan already did all this work, we used his adjustments for 2019, and then generated our own adjustments in a slightly simpler way for 2018.
```{r Bijon's Race Adjustments, cache=TRUE, echo=FALSE, message=FALSE, warning=FALSE}
######Bijon Race Adjustments

webpage<-read_html("https://bijanmazaheri.wordpress.com/2019/11/18/2019-diii-meet-adjustments-men/")
table_of_tables <- xml_find_all(webpage, "//table") %>% html_table
course_corrections<-as.data.frame(table_of_tables[[1]])
colnames(course_corrections)<-c("Meet", "Score")
course_corrections<-course_corrections %>% filter(Meet!="Meet")
```
Here, we filter our data further to only select the top 7 runners (the runners which ran at the national meet) for each team. We also make a number of slight modifications to the data set to clean up meet names, and correct for a mistake with a single Williams meet (domain specific knowledge!).
```{r Data Consolidation and Adjustment, cache=TRUE, echo=FALSE, message=FALSE, warning=FALSE}
#########################
###get teams that qualified and only select their top 7 runners
#########################
all_results<-read.csv("2019_all_results3.csv")
###Get teams who qualified to nationals
url="https://www.tfrrs.org/results/xc/16726/NCAA_Division_III_Cross_Country_Championships"
webpage <- read_html(url)
print("read webpage")
table_of_tables <- xml_find_all(webpage, "//table") %>% html_table
teams=table_of_tables[[1]]$Team
all_results<-all_results %>% filter(TEAM %in% teams)
#filter for runners who ran at nationals
runners=table_of_tables[[2]]$NAME
filtered_results<-all_results %>% filter(NAME %in% runners)
###Mutate MEETNAME column so that it matches Bijan's Course Corrections
filtered_results<- filtered_results %>% mutate(MEETNAME_CORR=str_replace_all(MEETNAME, " ", "_")) %>% mutate(MEETNAME_CORR=str_replace_all(MEETNAME_CORR, "/", ""))

filtered_results <- filtered_results %>% mutate(MEETNAME_CORR=ifelse(MEETNAME_CORR == "2019_Centennial_Conference_Championships", "2019_Centennial_Conference_Championships_", MEETNAME_CORR))

filtered_results <- filtered_results %>% mutate(MEETNAME_CORR=ifelse(MEETNAME_CORR == "Jim_Drews/Tori_Neubauer_Invitational", "Jim_DrewsTori_Neubauer_Invitational", MEETNAME_CORR))

filtered_results <- filtered_results %>% mutate(MEETNAME_CORR=ifelse(MEETNAME_CORR == "Williams_Invitational", "NESCAC_Cross_Country_Championships", MEETNAME_CORR))

filtered_results <- filtered_results %>% mutate(MEETNAME_CORR=ifelse(MEETNAME_CORR == "Rhodes_College_Cross_Country_Invitational", "Rhodes_College_Cross_Country_Invitational_", MEETNAME_CORR))

filtered_results <- filtered_results %>% filter(MEETNAME != "2019 ACAA Conference Cross Country Championships
" & MEETNAME != "NCAA Division III Cross Country Championships")

filtered_results <- filtered_results %>% mutate(MEETNAME_CORR=ifelse(MEETNAME_CORR == "Rhodes_College_Cross_Country_Invitational", "Rhodes_College_Cross_Country_Invitational_", MEETNAME_CORR))

filtered_results <-  left_join(filtered_results, course_corrections, 
                               by=c("MEETNAME_CORR" = "Meet"))

#write.csv(filtered_results, "2019_Results_Adjusted.csv")

```
Convert the times to seconds, and then apply the adjustment time.
```{r Lubridate, cache=TRUE, echo=FALSE, message=FALSE, warning=FALSE}
###Lubridate over the list

library(lubridate)
filtered_results <- filtered_results %>% mutate(ADJ_TIME=(period_to_seconds(ms(filtered_results$TIME))-as.numeric(filtered_results$Score)))

```
Split the results by name. Now we have a mapping of names to dataframes with race results, which we will use to simulate a national meet. 
```{r Split Results, cache=TRUE, echo=FALSE, message=FALSE, warning=FALSE}
####Now create split dataframe where each index is a runner and their races are included
split_results<-split(filtered_results, f=filtered_results$NAME, drop=TRUE)
```
Simulation time! For each person, we sample from a normal distribution centered on their average time from the season with a variance corresponding to their true variance throughout the year. One thing that we could change is the exact distribution we sample from for each athlete: it's far more likely to have a one-off horrible race than a one-off incredible race, so we could use a skewed distribution instead of a strictly normal distribution to model this. This would prevent any horrible, horrible days from allowing a runner to have an excellent simulated result on the other side of the center of the distribution. 
```{r SIMULATE, cache=TRUE, echo=FALSE, message=FALSE, warning=FALSE}
set.seed(11)
sim_stats<-list()
total_stats<-list()

for(count in seq(1, 100)) {
df <- data.frame(INDEX=numeric(), MEAN=numeric(), SD=numeric())
teams <- c()

for(i in seq(1, length(split_results))){

  personal.mean <- split_results[[i]] %>% group_by(NAME) %>% summarize(MEAN=mean(ADJ_TIME, na.rm=TRUE)) %>% pull()
  personal.sd <- split_results[[i]] %>% group_by(NAME) %>% summarize(SD=sd(ADJ_TIME, na.rm = TRUE)) %>% pull()
  teams <- append(teams, as.character(split_results[[i]]$TEAM[1]))
  df[nrow(df) + 1,] = c(i, personal.mean, personal.sd)
}


df$NAMES <- names(split_results)
df$TEAMS <- teams

sim.df <- data.frame(SIMTIME=numeric())

##one iteration of the sim we want to do
for(j in seq(1, nrow(df))) {
    sim.df[nrow(sim.df) + 1,] = c(rnorm(1, df$MEAN[j], df$SD[j]))
}
sim.df$NAMES=names(split_results)
sim.df$TEAMS=df$TEAMS

ordered_results_simulated <- sim.df %>% arrange(SIMTIME)
ordered_results_simulated$SCORE = seq(1,nrow(ordered_results_simulated))

#keep adding rows to df for total and then group to get avg scores, place

team_scores <- arrange(ordered_results_simulated %>% group_by(TEAMS) %>% 
                        summarize(TEAM_SCORE=sum(head(SCORE, 5))), TEAM_SCORE)

sim_stats[[count]]<-data.frame(TEAMS=team_scores$TEAMS[1:4], PLACES=seq(1:4), SCORES=team_scores$TEAM_SCORE[1:4])

total_stats[[count]]<-data.frame(TEAMS=team_scores$TEAMS, PLACES=seq(1:length(team_scores$TEAMS)), SCORES=team_scores$TEAM_SCORE)
}

sim_stats = do.call(rbind, sim_stats)
#sim_stats$PLACES<-as.factor(sim_stats$PLACES)

total_stats=do.call(rbind, total_stats)
#total_stats$PLACES<-as.factor(total_stats$PLACES)
```

```{r Interactive Plot with Win Probabilities, cache=TRUE, echo=FALSE, message=FALSE, warning=FALSE}
#######
#Interactive Plotly Bar Chart w/ Various Place Probabilities
#######

b<-sim_stats %>% group_by(TEAMS) %>% summarize(On_Podium=n()/100, P_first=sum(PLACES==1)/100, P_second=sum(PLACES==2)/100, P_third=sum(PLACES==3)/100, P_fourth=sum(PLACES==4)/100) %>% dplyr::arrange(desc(On_Podium))


text<-c()
for (i in 1:dim(b)[1]){
text <- c(text, paste("Prob Podium:", b[i,2], "\n", "Prob 1st:", b[i,3], "\n", "Prob 2nd:", b[i,4], "\n", "Prob 3rd:", b[i,5], "\n", "Prob 4th:", b[i,6]))
}

dat <- data.frame(x=b$TEAMS, y=b$On_Podium, text=text)
dat$x <- factor(dat$x, levels = as.character(b$TEAMS))

q <- plot_ly(dat, x = ~x, y = ~y, type = 'bar', text = text,
        marker = list(color = c('rgb(85,13,152)', 'rgb(178,8,57)', 'rgb(232,168,8)', 'rgb(188,0,0)', 'rgb(13,43,129)', 'rgb(247,138,12)', 'rgb(31,56,107)', 'rgb(162,31,75)', 'rgb(0,115,96)', 'rgb(134,43,45)', 'rgb(245,130,43)', 'rgb(254,209,76)'),
                      line = list(color = 'rgb(8,48,107)',
                                  width = 1.5))) %>%
  layout(title = "Results of National Meet Simulations 2019",
         xaxis = list(title = ""),
         yaxis = list(title = "Probability of Podium"))

q

chart_link = api_create(q, filename="bar-text")
chart_link



```

```{r Plot of Over/Underperformers, cache=TRUE, echo=FALSE, message=FALSE, warning=FALSE}
full_teams<- total_stats %>% group_by(TEAMS) %>% summarize(Expected_Place=mean(as.numeric(PLACES)), SD_Simulated_Place=sd(as.numeric(PLACES))) %>% dplyr::arrange(Expected_Place)

url="https://www.tfrrs.org/results/xc/16726/NCAA_Division_III_Cross_Country_Championships"
webpage <- read_html(url)
print("read webpage")
table_of_tables <- xml_find_all(webpage, "//table") %>% html_table
natties_2019_results<-table_of_tables[[1]] %>% select(PL, Team, Score)

full_teams_plus_results<-left_join(full_teams, natties_2019_results, by=c("TEAMS"="Team"))

full_teams_plus_results<- full_teams_plus_results %>% mutate(Norm_Prob_Rank = pnorm(PL, mean=Expected_Place, sd=SD_Simulated_Place))

###Plot the major under/overperformers

ranking_jumps=full_teams_plus_results %>% dplyr::arrange(Norm_Prob_Rank) %>% mutate(Rankings_Jump=Expected_Place-PL) %>% arrange(desc(PL))

prob_ranks<-ranking_jumps$TEAMS
ranking_jumps$TEAMS<-factor(ranking_jumps$TEAMS, levels=prob_ranks)

ggplot(ranking_jumps, aes(x=TEAMS, y=Rankings_Jump))+geom_bar(aes(fill=Norm_Prob_Rank), stat="identity")+theme_bw()+scale_fill_gradientn(colours=diverge_hsv(12))+ggtitle("Overperformers and Underperformers at the National Meet 2019")+coord_flip()
```

```{r Redo Plot of Over/Underperformers, cache=TRUE, echo=FALSE, message=FALSE, warning=FALSE}
over_under_performers<-total_stats %>% group_by(TEAMS) %>% summarize(mean_Score=mean(SCORES), sd_Score=sd(SCORES)) %>% arrange(mean_Score)

url="https://www.tfrrs.org/results/xc/16726/NCAA_Division_III_Cross_Country_Championships"
webpage <- read_html(url)
table_of_tables <- xml_find_all(webpage, "//table") %>% html_table
natties_2019_results<-table_of_tables[[1]] %>% select(PL, Team, Score)

expected_vs_observed<-left_join(over_under_performers, natties_2019_results, by=c("TEAMS" = "Team"))

expected_vs_observed<-expected_vs_observed %>% group_by(TEAMS) %>% mutate(Prob_Result=pnorm(Score, mean=mean_Score, sd=sd_Score)) %>% arrange(Prob_Result)

prob_ranks<-expected_vs_observed$TEAMS
expected_vs_observed$TEAMS<-factor(expected_vs_observed$TEAMS, levels=prob_ranks)

ggplot(expected_vs_observed, aes(x=TEAMS, y=mean_Score-Score))+geom_bar(aes(fill=Prob_Result), stat="identity")+theme_bw()+scale_fill_gradientn(colours=diverge_hsv(12))+ggtitle("Overperformers and Underperformers at the National Meet 2019")+ylab("Improvement in Score vs Simulated Expectation")+coord_flip()
```

```{r Score Differential, cache=TRUE, echo=FALSE, message=FALSE, warning=FALSE}
#Look at Scoring Differentials
score_differential=sim_stats %>% filter(PLACES==2) %>% select(SCORES) - sim_stats %>% filter(PLACES==1) %>% select(SCORES)
champions=sim_stats %>% filter(PLACES==1)%>% select(TEAMS)
differentials=cbind(champions, score_differential)

differentials %>% group_by(TEAMS) %>% summarize(mean_diff=mean(SCORES))
```





*2018*
Repeat all of the above for the 2018 season.

```{r 2018, cache=TRUE, echo=FALSE, message=FALSE, warning=FALSE}
#Which teams were at Nationals in 2018?
url="https://www.tfrrs.org/results/xc/15028/NCAA_Division_III_Cross_Country_Championships%250A"
webpage <- read_html(url)
table_of_tables <- xml_find_all(webpage, "//table") %>% html_table
teamnames<-table_of_tables[[3]]$Team

#URLS
urls<-c("https://www.tfrrs.org/teams/IL_college_m_North_Central_IL.html",
        "https://www.tfrrs.org/teams/MO_college_m_Washington_U.html",
        "https://www.tfrrs.org/teams/WI_college_m_Wis_La_Crosse.html",
        "https://www.tfrrs.org/teams/xc/PA_college_m_Haverford.html",
        "https://www.tfrrs.org/teams/IA_college_m_Wartburg.html",
        "https://www.tfrrs.org/teams/xc/MA_college_m_Amherst.html",
        "https://www.tfrrs.org/teams/CA_college_m_Pomona_Pitzer.html",
        "https://www.tfrrs.org/teams/MA_college_m_Williams.html",
        "https://www.tfrrs.org/teams/MD_college_m_Johns_Hopkins.html",
        "https://www.tfrrs.org/teams/NY_college_m_Geneseo_St.html",
        "https://www.tfrrs.org/teams/WI_college_m_Wis_Eau_Claire.html",
        "https://www.tfrrs.org/teams/IL_college_m_U_of_Chicago.html",
        "https://www.tfrrs.org/teams/NY_college_m_RPI.html",
        "https://www.tfrrs.org/teams/MN_college_m_Carleton.html", 
        "https://www.tfrrs.org/teams/xc/VT_college_m_Middlebury.html",
        "https://www.tfrrs.org/teams/MA_college_m_MIT.html",
        "https://www.tfrrs.org/teams/TN_college_m_Rhodes.html",
        "https://www.tfrrs.org/teams/xc/PA_college_m_Carnegie_Mellon.html",
        "https://www.tfrrs.org/teams/xc/MI_college_m_Calvin.html", 
        "https://www.tfrrs.org/teams/IN_college_m_DePauw.html",
        "https://www.tfrrs.org/teams/xc/OH_college_m_Case_Western.html",
        "https://www.tfrrs.org/teams/xc/WI_college_m_Wis_Stout.html",
        "https://www.tfrrs.org/teams/xc/MN_college_m_St_Olaf.html",
        "https://www.tfrrs.org/teams/xc/KY_college_m_Berea.html",
        "https://www.tfrrs.org/teams/MA_college_m_Tufts.html",
        "https://www.tfrrs.org/teams/xc/ME_college_m_Bates.html",
        "https://www.tfrrs.org/teams/CA_college_m_Claremont_Mudd_Scripps.html", 
        "https://www.tfrrs.org/teams/OH_college_m_Otterbein.html",
        "https://www.tfrrs.org/teams/xc/NY_college_m_Oneonta.html",
        "https://www.tfrrs.org/teams/xc/MN_college_m_St_Thomas.html",
        "https://www.tfrrs.org/teams/xc/GA_college_m_Emory.html",
        "https://www.tfrrs.org/teams/NY_college_m_RIT.html")

#get results links
team_races<-list()
for(url in urls) {
  print(url)
  webpage <- read_html(url)
  print("read webpage")
  links_tmp=str_match_all(webpage, "<a href=\"(.*?)\"")
  links=links_tmp[[1]][,2]
  links=links[grepl("/results/", links)]
  links=unique(links)
  links=links[setdiff(1:length(links), grep('[[:digit:]]{5}/[[:digit:]]{6}', links))]
  table_of_tables <- xml_find_all(webpage, "//table") %>% html_table
  index=grep("DATE", table_of_tables)
  dates_and_links=table_of_tables[[index]]
  dates_and_links<-cbind(dates_and_links, links)
  dates_and_links<-dates_and_links %>% filter(grepl("/results/xc/", dates_and_links$links))
  name=stringr::str_split(url, "_m_")[[1]][2]
  name=stringr::str_split(name, ".html")[[1]][1]
  dates_and_links=dates_and_links %>% filter(grepl(2018, dates_and_links$DATE))
  dates_and_links$links<-paste("https:", gsub("%0A", "%250A", dates_and_links$links), sep="")
  team_races[[name]]<-dates_and_links
}

#get correct teamnames
indices<-c()
for (i in 1:length(names(team_races))){
  if(str_sub(as.character(names(team_races)[i]), -4, -1)=="l_IL"){indices<-c(indices, 1)}
  else if(str_sub(as.character(names(team_races)[i]), -4, -1)=="o_St"){indices<-c(indices, 10)}
  else if(str_sub(as.character(names(team_races)[i]), -4, -1)=="on_U"){indices<-c(indices, 2)}
else{indices<-c(indices, grep(str_sub(as.character(names(team_races)[i]), -4, -1), teamnames))}
}

names(team_races)<-teamnames[indices]


###########
#GET RESULTS
###########

season_results<-list()

#for course corrections
resdf <- data.frame(PL=integer(),
                 NAME=character(),
                 YEAR=character(),
                 TEAM=character(),
                 TIME=character(),
                 COURSE=character(),
                 DATE=character(),
                 MEETNAME=character()
)
                 
for (j in 1:length(team_races)){
racelinks<-team_races[[j]]$links
print(names(team_races)[j])

#for getting results that we want to play around with
tmpdf <- data.frame(PL=integer(),
                 NAME=character(),
                 YEAR=character(),
                 TEAM=character(),
                 TIME=character(),
                 COURSE=character(),
                 DATE=character(),
                 MEETNAME=character()
)


for(url in racelinks) {
  print(names(team_races)[j])
  print(url)
  webpage <- read_html(url)
  print("read webpage")
  table_of_tables <- xml_find_all(webpage, "//table") %>% html_table
  titles <- html_nodes(webpage, "h3")
  meetnamelinks <-html_nodes(webpage, "a")
  courses <- html_nodes(webpage, ".inline-block")
    #generate possible indices
    
    if(length(titles)>length(table_of_tables)){titles=titles[2:length(titles)]}
    if(length(titles)<length(table_of_tables)){function(){}}
    else{
    poss_indices=grep("8K|8000|8,000|8k", titles)
    if (length(poss_indices)==0){function(){}}
    else{
      for(i in 1:length(poss_indices)) {
      if(grepl("Individual", titles[poss_indices[i]])) {
        table_index <- poss_indices[i]
        print(table_index)
        current_data <- table_of_tables[[table_index]] %>% select(NAME, YEAR, TEAM, TIME)
        current_data <- current_data %>% mutate(DATE=html_text(courses[4][1]))
        current_data <- current_data %>% mutate(MEETNAME=html_text(meetnamelinks[[14]]))
        if(str_length(html_text(courses[5][1])) > 4) {
          current_data <- current_data %>% mutate(COURSE=html_text(courses[5][1]))
        } else {
          current_data <- current_data %>% mutate(COURSE="NA")
        }
      tmpdf <-rbind (tmpdf, current_data)
      resdf <- rbind(resdf, current_data)
    }}
  }
}
}
season_results[[j]]<-tmpdf %>% filter(TEAM==names(team_races)[j])
}


all_results <- data.frame(NAME=character(),
                 YEAR=character(),
                 TEAM=character(),
                 TIME=character(),
                 COURSE=character(),
                 DATE=character(),
                 MEETNAME=character())

for(i in seq(1, 32)) {
    all_results = rbind(all_results, season_results[[i]])
}

all_results <- all_results %>% mutate(MEETNAME=str_trim(MEETNAME))
write.csv(all_results, "2018_all_results.csv")

```

```{r Course Corrections, cache=TRUE, echo=FALSE, message=FALSE, warning=FALSE}
###Correction is median difference in times between national meet and meet in question (for those who ran both) 
resdf<-resdf %>% distinct()
corrected<-matrix(ncol=86)
for (i in 1:length(unique(resdf$MEETNAME))){
  meet_one<-resdf %>% filter(MEETNAME==unique(resdf$MEETNAME)[i])
  meet_one$TIME<-period_to_seconds(ms(meet_one$TIME))
  tmpvec<-c()
  for (j in 1:length(unique(resdf$MEETNAME))){
  meet_two<-resdf %>% filter(MEETNAME==unique(resdf$MEETNAME)[j]) %>% distinct()
  meet_two$TIME<-period_to_seconds(ms(meet_two$TIME))
  tmp=inner_join(meet_one, meet_two, by="NAME") 
  tmpvec<-c(tmpvec, median(tmp$TIME.x-tmp$TIME.y, na.rm=TRUE))
  }
  corrected<-rbind(corrected, tmpvec)
}

corrected<-corrected[2:dim(corrected)[1],]
corrections<-corrected[1,]
names(corrections)<-unique(resdf$MEETNAME)
corrections<-corrections[!is.na(corrections)]

########
#Adjust course times
########
#Nationals 2018
url="https://www.tfrrs.org/results/xc/15028/NCAA_Division_III_Cross_Country_Championships%250A"
webpage <- read_html(url)
table_of_tables <- xml_find_all(webpage, "//table") %>% html_table
runners<-table_of_tables[[4]]$NAME

#factor in course adjustments
all_results<-read.csv("2018_all_results.csv")
all_results<- all_results %>% filter(NAME %in% runners)
indices=match(all_results$MEETNAME, str_trim(names(corrections)))
adjusted_results <- all_results %>% mutate(ADJ_TIME=period_to_seconds(ms(TIME))+corrections[indices])
#write.csv(adjusted_results, "2018_Results_Adjusted.csv")

#Split by name
split_results_18<-split(adjusted_results, f=adjusted_results$NAME, drop=TRUE)
```

```{r Simulate, cache=TRUE, echo=FALSE, message=FALSE, warning=FALSE}
set.seed(11)
sim_stats<-list()
total_stats<-list()

for(count in seq(1, 100)) {
df <- data.frame(INDEX=numeric(), MEAN=numeric(), SD=numeric())
teams <- c()

for(i in seq(1, length(split_results))){

  personal.mean <- split_results_18[[i]] %>% group_by(NAME) %>% summarize(MEAN=mean(ADJ_TIME, na.rm=TRUE)) %>% pull()
  personal.sd <- split_results_18[[i]] %>% group_by(NAME) %>% summarize(SD=sd(ADJ_TIME, na.rm = TRUE)) %>% pull()
  teams <- append(teams, as.character(split_results_18[[i]]$TEAM[1]))
  df[nrow(df) + 1,] = c(i, personal.mean, personal.sd)
}


df$NAMES <- names(split_results)
df$TEAMS <- teams

sim.df <- data.frame(SIMTIME=numeric())

##one iteration of the sim we want to do
for(j in seq(1, nrow(df))) {
    sim.df[nrow(sim.df) + 1,] = c(rnorm(1, df$MEAN[j], df$SD[j]))
}
sim.df$NAMES=names(split_results_18)
sim.df$TEAMS=df$TEAMS

ordered_results_simulated <- sim.df %>% arrange(SIMTIME)
ordered_results_simulated$SCORE = seq(1,nrow(ordered_results_simulated))

#keep adding rows to df for total and then group to get avg scores, place

team_scores <- arrange(ordered_results_simulated %>% group_by(TEAMS) %>% 
                        summarize(TEAM_SCORE=sum(head(SCORE, 5))), TEAM_SCORE)

sim_stats[[count]]<-data.frame(TEAMS=team_scores$TEAMS[1:4], PLACES=seq(1:4), SCORES=team_scores$TEAM_SCORE[1:4])

total_stats[[count]]<-data.frame(TEAMS=team_scores$TEAMS, PLACES=seq(1:length(team_scores$TEAMS)), SCORES=team_scores$TEAM_SCORE)
}

sim_stats = do.call(rbind, sim_stats)
sim_stats$PLACES<-as.factor(sim_stats$PLACES)

total_stats=do.call(rbind, total_stats)
total_stats$PLACES<-as.factor(total_stats$PLACES)

```

```{r Interactive Plot with Win Probabilities 2018, cache=TRUE, echo=FALSE, message=FALSE, warning=FALSE}
b<-sim_stats %>% group_by(TEAMS) %>% summarize(On_Podium=n()/100, P_first=sum(PLACES==1)/100, P_second=sum(PLACES==2)/100, P_third=sum(PLACES==3)/100, P_fourth=sum(PLACES==4)/100) %>% dplyr::arrange(desc(On_Podium))


text<-c()
for (i in 1:dim(b)[1]){
text <- c(text, paste("Prob Podium:", b[i,2], "\n", "Prob 1st:", b[i,3], "\n", "Prob 2nd:", b[i,4], "\n", "Prob 3rd:", b[i,5], "\n", "Prob 4th:", b[i,6]))
}

dat <- data.frame(x=b$TEAMS, y=b$On_Podium, text=text)
dat$x <- factor(dat$x, levels = as.character(b$TEAMS))

q <- plot_ly(dat, x = ~x, y = ~y, type = 'bar', text = text,
        marker = list(color = c('rgb(178,8,57)', 'rgb(0,115,96)', 'rgb(162,31,75)', 'rgb(204,21,69)', 'rgb(242,206,15)', 'rgb(13,43,129)', 'rgb(71,11,119)', 'rgb(31,56,107)', 'rgb(99,35,153)','rgb(226,30,21)', 'rgb(245,130,43)', 'rgb(188,0,0)', 'rgb(124,20,21)', 'rgb(238,173,18)'),
                      line = list(color = 'rgb(8,48,107)',
                                  width = 1.5))) %>%
  layout(title = "Results of National Meet Simulations 2018",
         xaxis = list(title = ""),
         yaxis = list(title = "Probability of Podium"))

q
```

```{r Over/UnderPerformers 2018, cache=TRUE, echo=FALSE, message=FALSE, warning=FALSE}
over_under_performers<-total_stats %>% group_by(TEAMS) %>% summarize(mean_Score=mean(SCORES), sd_Score=sd(SCORES)) %>% arrange(mean_Score)

url="https://www.tfrrs.org/results/xc/15028/NCAA_Division_III_Cross_Country_Championships%250A"
webpage <- read_html(url)
print("read webpage")
table_of_tables <- xml_find_all(webpage, "//table") %>% html_table
natties_2018_results<-table_of_tables[[3]] %>% select(PL, Team, Score)

expected_vs_observed<-left_join(over_under_performers, natties_2018_results, by=c("TEAMS" = "Team"))

expected_vs_observed<-expected_vs_observed %>% group_by(TEAMS) %>% mutate(Prob_Result=pnorm(Score, mean=mean_Score, sd=sd_Score)) %>% arrange(Prob_Result)

prob_ranks<-expected_vs_observed$TEAMS
expected_vs_observed$TEAMS<-factor(expected_vs_observed$TEAMS, levels=prob_ranks)

ggplot(expected_vs_observed, aes(x=TEAMS, y=mean_Score-Score))+geom_bar(aes(fill=Prob_Result), stat="identity")+theme_bw()+scale_fill_gradientn(colours=diverge_hsv(12))+ggtitle("Overperformers and Underperformers at the National Meet 2018")+ylab("Improvement in Score vs Simulated Expectation")+coord_flip()
```


*Exploring potential of Travel Distance*

```{r}
devtools::install_github("dkahle/ggmap")
library(ggmap)


places<-data.frame(LOCATIONS=paste(c(intersect(c$TEAM, d$TEAM), "Oshkosh", "Louisville")), Coordinates=list(c(41.772769, -88.143896), c(38.648823, -90.310903), c(43.817551, -91.231014), c(40.009308, -75.307651), c(42.728922, -92.482281), c(42.370855, -72.517003)))

key="AIzaSyB0T31gsbwbcHGWuejaGYUe5pEekr3BRwk"

set.seed(10)
c<-read.csv("2018_Results_Adjusted.csv")
d<-read.csv("2019_Results_Adjusted.csv")

coords<-c(c(41.772769, -88.143896), c(38.648823, -90.310903), c(43.817551, -91.231014), c(40.009308, -75.307651), c(42.728922, -92.482281), c(42.370855, -72.517003))

dfPoints=data.frame(lat=c(41.772769, 38.648823, 43.817551, 40.009308, 42.728922, 42.370855), long=c(-88.143896, -90.310903, -91.231014, -75.307651, -92.482281, -72.517003))
map("usa")
points(x = dfPoints$long, y = dfPoints$lat, col = "red")
lines(x = dfPoints$long, y = dfPoints$lat, col = "blue")
```

